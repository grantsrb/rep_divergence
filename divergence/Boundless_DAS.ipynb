{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63ff6846",
   "metadata": {},
   "source": [
    "## Boundless DAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae11b28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "__author__ = \"Zhengxuan Wu\"\n",
    "__version__ = \"10/05/2023\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d898fce",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This tutorial aims to reproduce one key result of [the Boundless DAS paper](https://arxiv.org/pdf/2305.08809). It uses the same pricing tag dataset as in the paper. Additionally, it focuses on finding alignment for the left boundary check only. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af5dff0",
   "metadata": {},
   "source": [
    "### Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e3c09e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This library is our indicator that the required installs\n",
    "# need to be done.\n",
    "import pyvene\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a39c2b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tutorial_price_tagging_utils import (\n",
    "    factual_sampler,\n",
    "    bound_alignment_sampler,\n",
    "    lower_bound_alignment_example_sampler,\n",
    ")\n",
    "\n",
    "from pyvene import (\n",
    "    IntervenableModel,\n",
    "    BoundlessRotatedSpaceIntervention,\n",
    "    RepresentationConfig,\n",
    "    IntervenableConfig,\n",
    ")\n",
    "from pyvene import create_llama\n",
    "from pyvene import set_seed, count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "970a8f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4093c4d3f84740ba881e79bb61f3624b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "config, tokenizer, llama = create_llama()\n",
    "_ = llama.to(\"cuda\")  # single gpu\n",
    "_ = llama.eval()  # always no grad on the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f9a7da",
   "metadata": {},
   "source": [
    "### Factual performance of instruct-tuned LLaMA-7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7f5d9c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_prealign = factual_sampler(tokenizer, 5000, game=\"pricing_tag\")\n",
    "prealign_dataset = Dataset.from_dict(\n",
    "    {\"input_ids\": raw_prealign[0], \"labels\": raw_prealign[1]}\n",
    ")\n",
    "prealign_dataset.set_format(\"torch\", columns=[\"input_ids\", \"labels\"])\n",
    "prealign_dataloader = DataLoader(prealign_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4cb38ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [01:42<00:00,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING: THIS NEEDS TO BE GOOD!] prealign task accuracy: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_count = 0\n",
    "correct_count = 0\n",
    "with torch.no_grad():\n",
    "    for step, inputs in enumerate(tqdm(prealign_dataloader)):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(llama.device)\n",
    "\n",
    "        # aligning forward!\n",
    "        outputs = llama(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            labels=inputs[\"labels\"],\n",
    "        )\n",
    "\n",
    "        actual_test_labels = inputs[\"labels\"][:, -1]\n",
    "        pred_test_labels = torch.argmax(outputs.logits[:, -1], dim=-1)\n",
    "\n",
    "        correct_labels = actual_test_labels == pred_test_labels\n",
    "\n",
    "        total_count += len(correct_labels)\n",
    "        correct_count += correct_labels.sum().tolist()\n",
    "current_acc = round(correct_count / total_count, 2)\n",
    "print(f\"[WARNING: THIS NEEDS TO BE GOOD!] prealign task accuracy: {current_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d30b97",
   "metadata": {},
   "source": [
    "### Create training dataset for our trainable intervention (Boundless DAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79caade7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "###################\n",
    "# data loaders\n",
    "###################\n",
    "raw_data = bound_alignment_sampler(\n",
    "    tokenizer, 10000, [lower_bound_alignment_example_sampler]\n",
    ")\n",
    "\n",
    "raw_train = (\n",
    "    raw_data[0][:8000],\n",
    "    raw_data[1][:8000],\n",
    "    raw_data[2][:8000],\n",
    "    raw_data[3][:8000],\n",
    ")\n",
    "raw_eval = (\n",
    "    raw_data[0][8000:9000],\n",
    "    raw_data[1][8000:9000],\n",
    "    raw_data[2][8000:9000],\n",
    "    raw_data[3][8000:9000],\n",
    ")\n",
    "raw_test = (\n",
    "    raw_data[0][9000:],\n",
    "    raw_data[1][9000:],\n",
    "    raw_data[2][9000:],\n",
    "    raw_data[3][9000:],\n",
    ")\n",
    "train_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_train[0],\n",
    "        \"source_input_ids\": raw_train[1],\n",
    "        \"labels\": raw_train[2],\n",
    "        \"intervention_ids\": raw_train[3],  # we will not use this field\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    ")\n",
    "eval_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_eval[0],\n",
    "        \"source_input_ids\": raw_eval[1],\n",
    "        \"labels\": raw_eval[2],\n",
    "        \"intervention_ids\": raw_eval[3],  # we will not use this field\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=16,\n",
    ")\n",
    "test_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_test[0],\n",
    "        \"source_input_ids\": raw_test[1],\n",
    "        \"labels\": raw_test[2],\n",
    "        \"intervention_ids\": raw_test[3],  # we will not use this field\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e83259",
   "metadata": {},
   "source": [
    "### Boundless DAS on Position-aligned Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "296d0a11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simple_boundless_das_position_config(model_type, intervention_type, layer):\n",
    "    config = IntervenableConfig(\n",
    "        model_type=model_type,\n",
    "        representations=[\n",
    "            RepresentationConfig(\n",
    "                layer,              # layer\n",
    "                intervention_type,  # intervention type\n",
    "            ),\n",
    "        ],\n",
    "        intervention_types=BoundlessRotatedSpaceIntervention,\n",
    "    )\n",
    "    return config\n",
    "\n",
    "\n",
    "config = simple_boundless_das_position_config(\n",
    "    type(llama), \"block_output\", 15\n",
    ")\n",
    "intervenable = IntervenableModel(config, llama)\n",
    "intervenable.set_device(\"cuda\")\n",
    "intervenable.disable_model_gradients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "740e3724",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_total = int(len(train_dataloader) * 3)\n",
    "warm_up_steps = 0.1 * t_total\n",
    "optimizer_params = []\n",
    "for k, v in intervenable.interventions.items():\n",
    "    optimizer_params += [{\"params\": v[0].rotate_layer.parameters()}]\n",
    "    optimizer_params += [{\"params\": v[0].intervention_boundaries, \"lr\": 1e-2}]\n",
    "optimizer = torch.optim.Adam(optimizer_params, lr=1e-3)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warm_up_steps, num_training_steps=t_total\n",
    ")\n",
    "\n",
    "\n",
    "# You can define your custom compute_metrics function.\n",
    "def compute_metrics(eval_preds, eval_labels):\n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "    for eval_pred, eval_label in zip(eval_preds, eval_labels):\n",
    "        actual_test_labels = eval_label[:, -1]\n",
    "        pred_test_labels = torch.argmax(eval_pred[:, -1], dim=-1)\n",
    "        correct_labels = actual_test_labels == pred_test_labels\n",
    "        total_count += len(correct_labels)\n",
    "        correct_count += correct_labels.sum().tolist()\n",
    "    accuracy = round(correct_count / total_count, 2)\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "epochs = 3\n",
    "gradient_accumulation_steps = 4\n",
    "total_step = 0\n",
    "target_total_step = len(train_dataloader) * epochs\n",
    "temperature_start = 50.0\n",
    "temperature_end = 0.1\n",
    "temperature_schedule = (\n",
    "    torch.linspace(temperature_start, temperature_end, target_total_step)\n",
    "    .to(torch.bfloat16)\n",
    "    .to(\"cuda\")\n",
    ")\n",
    "intervenable.set_temperature(temperature_schedule[total_step])\n",
    "\n",
    "\n",
    "def calculate_loss(logits, labels):\n",
    "    shift_logits = logits[..., :, :].contiguous()\n",
    "    shift_labels = labels[..., :].contiguous()\n",
    "    # Flatten the tokens\n",
    "    loss_fct = CrossEntropyLoss()\n",
    "    shift_logits = shift_logits.view(-1, intervenable.model_config.vocab_size)\n",
    "    shift_labels = shift_labels.view(-1)\n",
    "    # Enable model parallelism\n",
    "    shift_labels = shift_labels.to(shift_logits.device)\n",
    "    loss = loss_fct(shift_logits, shift_labels)\n",
    "\n",
    "    for k, v in intervenable.interventions.items():\n",
    "        boundary_loss = 1.0 * v[0].intervention_boundaries.sum()\n",
    "    loss += boundary_loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cc2a247",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama trainable parameters:  0\n",
      "intervention trainable parameters:  16777218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0:   1%|▋                                                                                                                 | 3/500 [00:07<19:31,  2.36s/it, loss=1.02, acc=0.81]\n",
      "Epoch:   0%|                                                                                                                                                    | 0/3 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 12\u001b[0m         inputs[k] \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m b_s \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     14\u001b[0m _, counterfactual_outputs \u001b[38;5;241m=\u001b[39m intervenable(\n\u001b[1;32m     15\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]},\n\u001b[1;32m     16\u001b[0m     [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]}],\n\u001b[1;32m     17\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msources->base\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m80\u001b[39m},  \u001b[38;5;66;03m# swap 80th token\u001b[39;00m\n\u001b[1;32m     18\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "intervenable.model.train()  # train enables drop-off but no grads\n",
    "print(\"llama trainable parameters: \", count_parameters(intervenable.model))\n",
    "print(\"intervention trainable parameters: \", intervenable.count_parameters())\n",
    "train_iterator = trange(0, int(epochs), desc=\"Epoch\")\n",
    "for epoch in train_iterator:\n",
    "    epoch_iterator = tqdm(\n",
    "        train_dataloader, desc=f\"Epoch: {epoch}\", position=0, leave=True\n",
    "    )\n",
    "    for step, inputs in enumerate(epoch_iterator):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(\"cuda\")\n",
    "        b_s = inputs[\"input_ids\"].shape[0]\n",
    "        _, counterfactual_outputs = intervenable(\n",
    "            {\"input_ids\": inputs[\"input_ids\"]},\n",
    "            [{\"input_ids\": inputs[\"source_input_ids\"]}],\n",
    "            {\"sources->base\": 80},  # swap 80th token\n",
    "        )\n",
    "        eval_metrics = compute_metrics(\n",
    "            [counterfactual_outputs.logits], [inputs[\"labels\"]]\n",
    "        )\n",
    "\n",
    "        # loss and backprop\n",
    "        loss = calculate_loss(counterfactual_outputs.logits, inputs[\"labels\"])\n",
    "        loss_str = round(loss.item(), 2)\n",
    "        epoch_iterator.set_postfix({\"loss\": loss_str, \"acc\": eval_metrics[\"accuracy\"]})\n",
    "\n",
    "        if gradient_accumulation_steps > 1:\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "        loss.backward()\n",
    "        if total_step % gradient_accumulation_steps == 0:\n",
    "            if not (gradient_accumulation_steps > 1 and total_step == 0):\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                intervenable.set_zero_grad()\n",
    "                intervenable.set_temperature(temperature_schedule[total_step])\n",
    "        total_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3323b113",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:  10%|█████████████▎                                                                                                                              | 6/63 [00:09<01:32,  1.62s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m         inputs[k] \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m b_s \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 13\u001b[0m base_outputs, counterfactual_outputs \u001b[38;5;241m=\u001b[39m intervenable(\n\u001b[1;32m     14\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]},\n\u001b[1;32m     15\u001b[0m     [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]}],\n\u001b[1;32m     16\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msources->base\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m80\u001b[39m},  \u001b[38;5;66;03m# swap 80th token\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     output_original_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m eval_labels \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     21\u001b[0m eval_preds \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [counterfactual_outputs\u001b[38;5;241m.\u001b[39mlogits]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/src/pyvene_fork/pyvene/models/intervenable_base.py:1937\u001b[0m, in \u001b[0;36mIntervenableModel.forward\u001b[0;34m(self, base, sources, unit_locations, source_representations, subspaces, labels, output_original_output, return_dict, use_cache, output_hidden_states)\u001b[0m\n\u001b[1;32m   1934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs \u001b[38;5;129;01mand\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1935\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m output_hidden_states\n\u001b[0;32m-> 1937\u001b[0m counterfactual_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel( \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbase, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs, )\n\u001b[1;32m   1939\u001b[0m set_handlers_to_remove\u001b[38;5;241m.\u001b[39mremove()\n\u001b[1;32m   1941\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_validation()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:940\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    939\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict_passed\n\u001b[0;32m--> 940\u001b[0m output \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    942\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:459\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Unpack[TransformersKwargs],\n\u001b[1;32m    441\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CausalLMOutputWithPast:\n\u001b[1;32m    442\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;124;03m    ```\"\"\"\u001b[39;00m\n\u001b[0;32m--> 459\u001b[0m     outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m    460\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    461\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    462\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m    463\u001b[0m         past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m    464\u001b[0m         inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m    465\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    466\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m    467\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    468\u001b[0m     )\n\u001b[1;32m    470\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:1064\u001b[0m, in \u001b[0;36mcheck_model_inputs.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1061\u001b[0m                 module\u001b[38;5;241m.\u001b[39mforward \u001b[38;5;241m=\u001b[39m make_capture_wrapper(module, original_forward, key, specs\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   1062\u001b[0m                 monkey_patched_layers\u001b[38;5;241m.\u001b[39mappend((module, original_forward))\n\u001b[0;32m-> 1064\u001b[0m outputs \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;66;03m# Restore original forward methods\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module, original_forward \u001b[38;5;129;01min\u001b[39;00m monkey_patched_layers:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:395\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, cache_position, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_emb(hidden_states, position_ids)\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers]:\n\u001b[0;32m--> 395\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[1;32m    396\u001b[0m         hidden_states,\n\u001b[1;32m    397\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcausal_mask,\n\u001b[1;32m    398\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m    399\u001b[0m         past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m    400\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m    401\u001b[0m         position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    403\u001b[0m     )\n\u001b[1;32m    405\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(hidden_states)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[1;32m    407\u001b[0m     last_hidden_state\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    408\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m    409\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_layers.py:94\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning_once(message)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1879\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1878\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1881\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1882\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1883\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1884\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1838\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1835\u001b[0m     called_always_called_hooks\u001b[38;5;241m.\u001b[39madd(hook_id)\n\u001b[1;32m   1837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks_with_kwargs \u001b[38;5;129;01mor\u001b[39;00m hook_id \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks_with_kwargs:\n\u001b[0;32m-> 1838\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[1;32m   1839\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1840\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, result)\n",
      "File \u001b[0;32m~/src/pyvene_fork/pyvene/models/intervenable_base.py:1540\u001b[0m, in \u001b[0;36mIntervenableModel._intervention_setter.<locals>.hook_callback\u001b[0;34m(model, args, kwargs, output)\u001b[0m\n\u001b[1;32m   1537\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1538\u001b[0m         output \u001b[38;5;241m=\u001b[39m args\n\u001b[0;32m-> 1540\u001b[0m selected_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather_intervention_output(\n\u001b[1;32m   1541\u001b[0m     output, key, unit_locations_base[key_i]\n\u001b[1;32m   1542\u001b[0m )\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;66;03m# TODO: need to figure out why clone is needed\u001b[39;00m\n\u001b[1;32m   1544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_model_stateless:\n",
      "File \u001b[0;32m~/src/pyvene_fork/pyvene/models/intervenable_base.py:488\u001b[0m, in \u001b[0;36mBaseModel._gather_intervention_output\u001b[0;34m(self, output, representations_key, unit_locations)\u001b[0m\n\u001b[1;32m    478\u001b[0m     original_output \u001b[38;5;241m=\u001b[39m output_to_subcomponent(\n\u001b[1;32m    479\u001b[0m         original_output,\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepresentations[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config,\n\u001b[1;32m    485\u001b[0m     )\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;66;03m# gather based on intervention locations\u001b[39;00m\n\u001b[0;32m--> 488\u001b[0m     selected_output \u001b[38;5;241m=\u001b[39m gather_neurons(\n\u001b[1;32m    489\u001b[0m         original_output,\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepresentations[\n\u001b[1;32m    491\u001b[0m             representations_key\n\u001b[1;32m    492\u001b[0m         ]\u001b[38;5;241m.\u001b[39munit,\n\u001b[1;32m    493\u001b[0m         unit_locations,\n\u001b[1;32m    494\u001b[0m         device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_device()\n\u001b[1;32m    495\u001b[0m     )\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m selected_output\n",
      "File \u001b[0;32m~/src/pyvene_fork/pyvene/models/modeling_utils.py:295\u001b[0m, in \u001b[0;36mgather_neurons\u001b[0;34m(tensor_input, unit, unit_locations_as_list, device)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor_output  \u001b[38;5;66;03m# b, num_unit (h), num_unit (pos), d\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     unit_locations \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m    296\u001b[0m         unit_locations_as_list, device\u001b[38;5;241m=\u001b[39mtensor_input\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m device\n\u001b[1;32m    297\u001b[0m     )\n\u001b[1;32m    299\u001b[0m     tensor_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    300\u001b[0m         tensor_input,\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m         )\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39mtensor_input\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:]),\n\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor_output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# evaluation on the test set\n",
    "eval_labels = []\n",
    "eval_preds = []\n",
    "base_hstates = []\n",
    "intrv_hstates = []\n",
    "with torch.no_grad():\n",
    "    epoch_iterator = tqdm(test_dataloader, desc=f\"Test\")\n",
    "    for step, inputs in enumerate(epoch_iterator):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(\"cuda\")\n",
    "        b_s = inputs[\"input_ids\"].shape[0]\n",
    "        base_outputs, counterfactual_outputs = intervenable(\n",
    "            {\"input_ids\": inputs[\"input_ids\"]},\n",
    "            [{\"input_ids\": inputs[\"source_input_ids\"]}],\n",
    "            {\"sources->base\": 80},  # swap 80th token\n",
    "            output_original_output=True,\n",
    "            output_hidden_states=True,\n",
    "        )\n",
    "        eval_labels += [inputs[\"labels\"]]\n",
    "        eval_preds += [counterfactual_outputs.logits]\n",
    "        base_hstates.append([h.cpu() for h in base_outputs.hidden_states])\n",
    "        intrv_hstates.append([h.cpu() for h in counterfactual_outputs.hidden_states])\n",
    "eval_metrics = compute_metrics(eval_preds, eval_labels)\n",
    "print(eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351526e8-2795-46dc-85b1-9152ee306937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fbd6296",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'intrv_hstates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(intrv_hstates[\u001b[38;5;241m0\u001b[39m])):\n\u001b[1;32m      2\u001b[0m     do_break \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(intrv_hstates[\u001b[38;5;241m0\u001b[39m][layer]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'intrv_hstates' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "for layer in range(len(intrv_hstates[0])):\n",
    "    do_break = False\n",
    "    for pos in range(intrv_hstates[0][layer].shape[1]):\n",
    "        if not torch.all( intrv_hstates[0][layer][:,pos] == base_hstates[0][layer][:,pos] ):\n",
    "            d = base_hstates[0][layer].shape[-1]\n",
    "            natty_states = [base_hstates[i][layer][:,pos].reshape(-1,d) for i in range(len(base_hstates))]\n",
    "            intrv_states = [intrv_hstates[i][layer][:,pos].reshape(-1,d) for i in range(len(base_hstates))]\n",
    "            print(\"L:\", layer, \"Pos:\", pos)\n",
    "            do_break = True\n",
    "            break\n",
    "    if do_break: break\n",
    "natty_states = torch.vstack(natty_states)\n",
    "intrv_states = torch.vstack(intrv_states)\n",
    "print(intrv_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892716ed-40f0-496c-81b0-69eb06a4d9ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def interleave_scatter(\n",
    "    natty_df,\n",
    "    intrv_df,\n",
    "    hue=\"count\",\n",
    "    title=None,\n",
    "    samps_per_step=50,\n",
    "    incl_legend=False,\n",
    "    leg_loc=None,\n",
    "    leg_bbox_anchor=None,\n",
    "    leg_alpha=0.7,\n",
    "    fontsize=25,\n",
    "    titlesize=30,\n",
    "    legendsize=25,\n",
    "    ticksize=30,\n",
    "    labelsize=25,\n",
    "    save_name=None,\n",
    "    *args, **kwargs,\n",
    "):\n",
    "    #df = pd.DataFrame({\n",
    "    #    \"x\": samples[:,0],\n",
    "    #    \"y\": samples[:,1],\n",
    "    #    \"hue\": samples[:,1],\n",
    "    #})\n",
    "    #df[\"x\"] = (df[\"x\"]-np.mean(df[\"x\"]))\n",
    "    #df[\"hue\"] = df[\"hue\"]-np.min(df[\"hue\"])\n",
    "    #df[\"hue\"] = df[\"hue\"]/np.max(df[\"hue\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    alpha = 0.8,\n",
    "    dark = 0.2,\n",
    "    light = 0.85,\n",
    "    rot = 0,\n",
    "    intrv_cmap = sns.cubehelix_palette(start=-.3, rot=rot, dark=dark, light=light, reverse=True, as_cmap=True)\n",
    "    color = None\n",
    "    if hue is None:\n",
    "        color = intrv_cmap(0.7)\n",
    "    #intrv_cmap = sns.dark_palette(\"blue\", as_cmap=True)\n",
    "    sns.scatterplot(x=\"pc0\", y=\"pc1\", color=color, alpha=alpha, data=intrv_df, ax=ax, hue=hue, palette=intrv_cmap, edgecolor=\"none\")\n",
    "    \n",
    "    native_cmap = sns.cubehelix_palette(start=0.7, rot=rot, dark=dark, light=light, reverse=True, as_cmap=True)\n",
    "    if hue is None:\n",
    "        color = native_cmap(0.7)\n",
    "    #native_cmap = sns.dark_palette(\"red\", as_cmap=True)\n",
    "    sns.scatterplot(x=\"pc0\", y=\"pc1\", color=color, alpha=alpha, data=natty_df, ax=ax, hue=hue, palette=native_cmap, edgecolor=\"none\")\n",
    "                    #hue=\"hue\", palette=\"blue\")\n",
    "        \n",
    "    ## y divider\n",
    "    #ax.plot([0,0],[-1,5], \"k--\", alpha=0.5)\n",
    "    ## x dividers\n",
    "    #for i in y_values[:-1]:\n",
    "    #    y = i+0.5\n",
    "    #    ax.plot([-2,2],[y,y], \"k--\", alpha=0.5)\n",
    "    #plt.xlim([-2,2])\n",
    "    #plt.ylim([-0.75,4.75])\n",
    "    \n",
    "    plt.xlabel(\"\", fontsize=fontsize)\n",
    "    plt.ylabel(\"\", fontsize=fontsize)\n",
    "    \n",
    "    #plt.xticks([], fontsize=fontsize)\n",
    "    #plt.yticks([], fontsize=fontsize)\n",
    "    \n",
    "    # # Manually create colorbars / legend patches\n",
    "    # native_cmap = sns.cubehelix_palette(start=0.7, rot=rot, dark=dark, light=light, reverse=True, as_cmap=True)\n",
    "    # intrv_cmap = sns.cubehelix_palette(start=-.3, rot=rot, dark=dark, light=light, reverse=True, as_cmap=True)\n",
    "    \n",
    "    # Legend handles: colored rectangles with labels\n",
    "    native_patch = mpatches.Patch(color=native_cmap(0.8), label=\"Native\")\n",
    "    intrv_patch = mpatches.Patch(color=intrv_cmap(0.8), label=\"Intervened\")\n",
    "    \n",
    "    if not incl_legend:\n",
    "        plt.legend().set_visible(False)\n",
    "    else:\n",
    "        ax.legend(handles=[native_patch, intrv_patch], fontsize=legendsize, loc=\"upper right\", bbox_to_anchor=(1.75,1))\n",
    "    if save_name:\n",
    "        plt.savefig(save_name, dpi=600, bbox_inches=\"tight\")\n",
    "        print(\"Saved to\", save_name)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490cdb85-33d4-497f-b224-717ac34b0649",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Natty PCA\")\n",
    "X = np.concatenate([\n",
    "    natty_states.clone().detach().cpu().float().numpy(),\n",
    "    intrv_states.clone().detach().cpu().float().numpy(),\n",
    "], axis=0)\n",
    "train_X = X\n",
    "mu = train_X.mean(0)\n",
    "sig = train_X.std(0)+1e-5\n",
    "X = (X-mu)/(sig)\n",
    "train_X = (train_X-mu)/(sig)\n",
    "pca = PCA()\n",
    "pca.fit(train_X)\n",
    "\n",
    "vecs = pca.transform(X)\n",
    "natty_vecs = torch.tensor(vecs[:len(natty_states)])\n",
    "intrv_vecs = torch.tensor(vecs[len(natty_states):])\n",
    "\n",
    "natty_df = {\n",
    "    \"pc0\": natty_vecs[:,0],\n",
    "    \"pc1\": natty_vecs[:,1],\n",
    "    \"hue\": np.ones_like(natty_vecs[:,1]),\n",
    "}\n",
    "intrv_df = {\n",
    "    \"pc0\": intrv_vecs[:,0],\n",
    "    \"pc1\": intrv_vecs[:,1],\n",
    "    \"hue\": np.ones_like(natty_vecs[:,1]),\n",
    "}\n",
    "\n",
    "\n",
    "interleave_scatter(\n",
    "    natty_df,\n",
    "    intrv_df,\n",
    "    hue=None,\n",
    "    title=\"\", #f\"Neural Space {varb}\",\n",
    "    incl_legend=False,\n",
    "    save_name=os.path.join(\n",
    "        \"./\", f\"llama_boundless_pricetag.png\",\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76bb812a-371f-45fd-aba8-0baa98b0bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from geomloss import SamplesLoss\n",
    "except ModuleNotFoundError:\n",
    "    !pip install geomloss\n",
    "    from geomloss import SamplesLoss\n",
    "\n",
    "kwargs = { \"loss\": \"sinkhorn\", \"p\": 2, \"blur\": 0.05, }\n",
    "loss_fn = SamplesLoss(**kwargs)\n",
    "def get_emd(X,Y):\n",
    "    return loss_fn(X,Y).item()\n",
    "\n",
    "perm = torch.randperm(len(natty_vecs)).long()\n",
    "div = get_emd(natty_vecs, intrv_vecs)\n",
    "baseline = get_emd(natty_vecs[perm[:len(natty_vecs)//2]], natty_vecs[perm[len(natty_vecs)//2:]]) \n",
    "div_fraction = (div-baseline)/baseline\n",
    "print(\"Divergence:\", div)\n",
    "print(\"Baseline:\", baseline)\n",
    "print(\"% Divergence:\", div_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a45c673-f3e1-480d-a161-6de28d8bc60d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
