{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd3ecc8a",
   "metadata": {},
   "source": [
    "Specs for the notebook:\n",
    "- ideally takes any huggingface model but llama of some sort is good\n",
    "- produces the difference vectors\n",
    "- produces intervened vectors for entities/attributes\n",
    "- produces the corresponding native vectors for the entities/attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "184b0887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import gc\n",
    "import dataclasses\n",
    "import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "def load_model_and_tokenizer(gpu_num, model_name=\"meta-llama/Llama-2-7b-chat-hf\"):\n",
    "    device = torch.device(f\"cuda:{gpu_num}\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name, cache_dir=\"/data2/sjeromeh/cache/pretrained_models\"\n",
    "    ).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"/data2/sjeromeh/cache/pretrained_models\")\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    model.eval()\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def clear_hooks(input_hooks):\n",
    "    for hook in input_hooks:\n",
    "        hook.remove()\n",
    "    input_hooks = []\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e54882",
   "metadata": {},
   "source": [
    "Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62f8031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "model_alias = \"llama-2-7b-chat\"\n",
    "\n",
    "model, tokenizer = load_model_and_tokenizer(0, model_name=model_name)\n",
    "device = model.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b4b570",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b3bd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of countries: 45, Sample: [('Argentina', 'Buenos Aires'), ('Australia', 'Canberra'), ('Austria', 'Vienna'), ('Brazil', 'Brasília'), ('Canada', 'Ottawa')]\n",
      "Number of names: 60, Sample: ['Michael', 'James', 'John', 'Robert', 'David']\n"
     ]
    }
   ],
   "source": [
    "countries_df = pd.read_csv(\"data/countries.csv\")\n",
    "names_df = pd.read_csv(\"data/names.csv\", index_col=0)\n",
    "\n",
    "countries_to_capitals = countries_df.set_index(\"country\")[\"capital\"].to_dict()\n",
    "names = names_df[\"name\"].tolist()\n",
    "\n",
    "# Keep only single token countries and names\n",
    "countries_to_capitals = {k: v for k, v in countries_to_capitals.items() if len(tokenizer.encode(k, add_special_tokens=False)) == 1}\n",
    "names = [n for n in names if len(tokenizer.encode(n, add_special_tokens=False)) == 1]\n",
    "\n",
    "print(f\"Number of countries: {len(countries_to_capitals)}, Sample: {list(countries_to_capitals.items())[:5]}\")\n",
    "print(f\"Number of names: {len(names)}, Sample: {names[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea54a8c5",
   "metadata": {},
   "source": [
    "Prompt generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5b9d3f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt(context='Answer the question based on the context below. Keep the answer short.\\n\\nContext: Anthony lives in the capital city of Japan. Benjamin lives in the capital city of Egypt.', questions=['Question: Which city does Anthony live in?', 'Question: Which city does Benjamin live in?'], answers=['Tokyo', 'Cairo'], names=['Anthony', 'Benjamin'], countries=['Japan', 'Egypt'])\n",
      "Prompt(context='Answer the question based on the context below. Keep the answer short.\\n\\nContext: Elizabeth lives in the capital city of China. Carol lives in the capital city of Georgia.', questions=['Question: Which city does Elizabeth live in?', 'Question: Which city does Carol live in?'], answers=['Beijing', 'Tbilisi'], names=['Elizabeth', 'Carol'], countries=['China', 'Georgia'])\n"
     ]
    }
   ],
   "source": [
    "@dataclasses.dataclass(frozen=True)\n",
    "class Prompt:\n",
    "    context: str\n",
    "    questions: list[str]\n",
    "    answers: list[str]\n",
    "    names: list[str]\n",
    "    countries: list[str]\n",
    "\n",
    "\n",
    "def generate_prompt_pair(num_entities):\n",
    "    cs = random.sample(list(countries_to_capitals.keys()), num_entities*2)\n",
    "    ns = random.sample(names, num_entities*2)\n",
    "\n",
    "    cs_1 = cs[:num_entities]\n",
    "    ns_1 = ns[:num_entities]\n",
    "    cs_2 = cs[num_entities:]\n",
    "    ns_2 = ns[num_entities:]\n",
    "\n",
    "    es_1 = [f\"{n} lives in the capital city of {c}.\" for c, n in zip(cs_1, ns_1)]\n",
    "    es_2 = [f\"{n} lives in the capital city of {c}.\" for c, n in zip(cs_2, ns_2)]\n",
    "    target_context =  f\"Answer the question based on the context below. Keep the answer short.\\n\\nContext: {' '.join(es_1)}\"\n",
    "    source_context =  f\"Answer the question based on the context below. Keep the answer short.\\n\\nContext: {' '.join(es_2)}\"\n",
    "    target_questions = [f\"Question: Which city does {n} live in?\" for n in ns_1]\n",
    "    source_questions = [f\"Question: Which city does {n} live in?\" for n in ns_2]\n",
    "    target_answers = [countries_to_capitals[c] for c in cs_1]\n",
    "    source_answers = [countries_to_capitals[c] for c in cs_2]\n",
    "    return (Prompt(\n",
    "        context=target_context,\n",
    "        questions=target_questions,\n",
    "        answers=target_answers,\n",
    "        names=ns_1,\n",
    "        countries=cs_1,\n",
    "    ), Prompt(\n",
    "        context=source_context,\n",
    "        questions=source_questions,\n",
    "        answers=source_answers,\n",
    "        names=ns_2,\n",
    "        countries=cs_2,\n",
    "    ))\n",
    "\n",
    "target_prompt, source_prompt = generate_prompt_pair(2)\n",
    "print(target_prompt)\n",
    "print(source_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c93330d",
   "metadata": {},
   "source": [
    "Patching experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0eb20ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_outputs(layer: int, save_map: dict):\n",
    "    \"\"\"Hook function for saving the output of a model component\"\"\"\n",
    "    def hook_fn(module, input, output):\n",
    "        if isinstance(output, tuple):\n",
    "            proj_output = output[0]\n",
    "        else:\n",
    "            proj_output = output\n",
    "\n",
    "        save_map[layer] = proj_output.clone()\n",
    "        return output\n",
    "    return hook_fn\n",
    "\n",
    "\n",
    "def save_hidden_states(ids, model):\n",
    "    \"\"\"Save the hidden states of a model. Returns model output and a (num_layers,num_tokens,hidden_size) tensor of hidden states.\"\"\"\n",
    "    hooks = []\n",
    "    hidden_states = {}\n",
    "    for layer in range(len(model.model.layers)):\n",
    "        hidden_state = model.model.layers[layer].post_attention_layernorm\n",
    "        hidden_state_hook_handle = hidden_state.register_forward_hook(save_outputs(layer, hidden_states))\n",
    "        hooks.append(hidden_state_hook_handle)\n",
    "    with torch.no_grad():\n",
    "        out = model(\n",
    "            ids,\n",
    "            attention_mask=torch.ones_like(ids),\n",
    "        )\n",
    "    clear_hooks(hooks)\n",
    "    hidden_states_tensor = torch.stack([hidden_states[i] for i in range(len(hidden_states))], dim=0).squeeze(1)\n",
    "    return out, hidden_states_tensor\n",
    "\n",
    "\n",
    "def modify_outputs(layer: int, target_layers: list[int], target_position: int, original_hidden_states: dict, modified_hidden_states: dict):\n",
    "    \"\"\"Hook function for replacing hidden states of a target layer at a target position with the hidden states from a modified prompt.\"\"\"\n",
    "    def hook_fn(module, input, output):\n",
    "        if isinstance(output, tuple):\n",
    "            proj_output = output[0]\n",
    "        else:\n",
    "            proj_output = output\n",
    "\n",
    "        proj_output = original_hidden_states[layer].clone()\n",
    "        if layer in target_layers:\n",
    "            proj_output[target_position,:] = modified_hidden_states[layer,target_position,:].clone()\n",
    "\n",
    "        if isinstance(proj_output, tuple):\n",
    "            return (proj_output,) + output[1:]\n",
    "        else:\n",
    "            return proj_output\n",
    "    return hook_fn\n",
    "\n",
    "\n",
    "def modify_hidden_states(ids, model, target_position, original_hidden_states, modified_hidden_states):\n",
    "    \"\"\"Modify the hidden states of a model. Returns model output.\"\"\"\n",
    "    hooks = []\n",
    "    for layer in range(len(model.model.layers)):\n",
    "        hidden_state = model.model.layers[layer].post_attention_layernorm\n",
    "        hidden_state_hook_handle = hidden_state.register_forward_hook(modify_outputs(layer, list(range(len(model.model.layers))), target_position, original_hidden_states, modified_hidden_states))\n",
    "        hooks.append(hidden_state_hook_handle)\n",
    "    with torch.no_grad():\n",
    "        out = model(\n",
    "            ids,\n",
    "            attention_mask=torch.ones_like(ids),\n",
    "        )\n",
    "    clear_hooks(hooks)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d63df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 96/100 [05:14<00:13,  3.37s/it]"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "nruns = 100\n",
    "for run in tqdm.tqdm(range(nruns)):\n",
    "    \n",
    "    mp, ap = generate_prompt_pair(2)\n",
    "    for query_entity_idx in range(4):\n",
    "        \n",
    "        query_entities = mp.names + ap.names\n",
    "        questions = mp.questions + ap.questions\n",
    "        main_prompt = mp.context + \"\\n\" + questions[query_entity_idx] + f\"\\nAnswer: {query_entities[query_entity_idx]} lives in the city of\"\n",
    "        alt_prompt = ap.context + \"\\n\" + questions[query_entity_idx] + f\"\\nAnswer: {query_entities[query_entity_idx]} lives in the city of\"\n",
    "\n",
    "        main_prompt_tokens = tokenizer(main_prompt, return_tensors=\"pt\").to(device)\n",
    "        alt_prompt_tokens = tokenizer(alt_prompt, return_tensors=\"pt\").to(device)\n",
    "        main_ids = main_prompt_tokens[\"input_ids\"]\n",
    "        alt_ids = alt_prompt_tokens[\"input_ids\"]\n",
    "\n",
    "        main_decoded_tokens = tokenizer.convert_ids_to_tokens(main_prompt_tokens[\"input_ids\"][0])\n",
    "        main_n1_index = main_decoded_tokens.index(f\"▁{mp.names[0]}\")\n",
    "        main_n2_index = main_decoded_tokens.index(f\"▁{mp.names[1]}\")\n",
    "        main_c1_index = main_decoded_tokens.index(f\"▁{mp.countries[0]}\")\n",
    "        main_c2_index = main_decoded_tokens.index(f\"▁{mp.countries[1]}\")\n",
    "        alt_decoded_tokens = tokenizer.convert_ids_to_tokens(alt_prompt_tokens[\"input_ids\"][0])\n",
    "        alt_n1_index = alt_decoded_tokens.index(f\"▁{ap.names[0]}\")\n",
    "        alt_n2_index = alt_decoded_tokens.index(f\"▁{ap.names[1]}\")\n",
    "        alt_c1_index = alt_decoded_tokens.index(f\"▁{ap.countries[0]}\")\n",
    "        alt_c2_index = alt_decoded_tokens.index(f\"▁{ap.countries[1]}\")\n",
    "        assert main_n1_index == alt_n1_index and main_n2_index == alt_n2_index and main_c1_index == alt_c1_index and main_c2_index == alt_c2_index\n",
    "\n",
    "        main_a1_id = tokenizer(mp.answers[0], add_special_tokens=False)[\"input_ids\"][0]\n",
    "        main_a2_id = tokenizer(mp.answers[1], add_special_tokens=False)[\"input_ids\"][0]\n",
    "        alt_a1_id = tokenizer(ap.answers[0], add_special_tokens=False)[\"input_ids\"][0]\n",
    "        alt_a2_id = tokenizer(ap.answers[1], add_special_tokens=False)[\"input_ids\"][0]\n",
    "\n",
    "        # Get hidden states\n",
    "        with torch.no_grad():\n",
    "            main_out, main_hidden_states = save_hidden_states(main_ids, model)\n",
    "            alt_out, alt_hidden_states = save_hidden_states(alt_ids, model)\n",
    "\n",
    "        for modify_index in [main_n1_index, main_n2_index, main_c1_index, main_c2_index]:\n",
    "\n",
    "            # Modify hidden states\n",
    "            modified_out = modify_hidden_states(main_ids, model, modify_index, main_hidden_states, alt_hidden_states)\n",
    "            modified_log_probs = F.log_softmax(modified_out.logits[0,-1,:], dim=-1)\n",
    "            rows += [\n",
    "                {\n",
    "                    \"run\": run,\n",
    "                    \"query_name\": [\"e0\", \"e1\", \"e0'\", \"e1'\"][query_entity_idx],\n",
    "                    \"attribute\": [\"a0\", \"a1\", \"a0'\", \"a1'\"][i],\n",
    "                    \"swap_type\": \"entity\" if modify_index in [main_n1_index, main_n2_index] else \"attribute\",\n",
    "                    \"swap_index\": 0 if modify_index in [main_n1_index, main_c1_index] else 1,\n",
    "                    \"log_prob\": modified_log_probs[a_id].item(),\n",
    "                } for i, a_id in enumerate([main_a1_id, main_a2_id, alt_a1_id, alt_a2_id])\n",
    "            ]\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(f\"binding_vectors_factorizability.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcd7d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df = df.groupby([\"query_name\", \"attribute\", \"swap_type\", \"swap_index\"]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ee4905bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_name</th>\n",
       "      <th>attribute</th>\n",
       "      <th>swap_type</th>\n",
       "      <th>swap_index</th>\n",
       "      <th>run</th>\n",
       "      <th>log_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e0</td>\n",
       "      <td>a0</td>\n",
       "      <td>entity</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-0.208787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e0</td>\n",
       "      <td>a0'</td>\n",
       "      <td>entity</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-15.826601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>e0</td>\n",
       "      <td>a1</td>\n",
       "      <td>entity</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-8.312859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>e0</td>\n",
       "      <td>a1'</td>\n",
       "      <td>entity</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-16.323290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>e0'</td>\n",
       "      <td>a0</td>\n",
       "      <td>entity</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-0.532698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>e0'</td>\n",
       "      <td>a0'</td>\n",
       "      <td>entity</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-12.923728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>e0'</td>\n",
       "      <td>a1</td>\n",
       "      <td>entity</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-3.503838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>e0'</td>\n",
       "      <td>a1'</td>\n",
       "      <td>entity</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-13.717681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>e1</td>\n",
       "      <td>a0</td>\n",
       "      <td>entity</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-8.421687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>e1</td>\n",
       "      <td>a0'</td>\n",
       "      <td>entity</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-17.091707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>e1</td>\n",
       "      <td>a1</td>\n",
       "      <td>entity</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-0.371906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>e1</td>\n",
       "      <td>a1'</td>\n",
       "      <td>entity</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-16.691963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>e1'</td>\n",
       "      <td>a0</td>\n",
       "      <td>entity</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-2.005777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>e1'</td>\n",
       "      <td>a0'</td>\n",
       "      <td>entity</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-11.650394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>e1'</td>\n",
       "      <td>a1</td>\n",
       "      <td>entity</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-2.338843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>e1'</td>\n",
       "      <td>a1'</td>\n",
       "      <td>entity</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-12.068946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_name attribute swap_type  swap_index  run   log_prob\n",
       "2          e0        a0    entity           0  4.5  -0.208787\n",
       "6          e0       a0'    entity           0  4.5 -15.826601\n",
       "10         e0        a1    entity           0  4.5  -8.312859\n",
       "14         e0       a1'    entity           0  4.5 -16.323290\n",
       "18        e0'        a0    entity           0  4.5  -0.532698\n",
       "22        e0'       a0'    entity           0  4.5 -12.923728\n",
       "26        e0'        a1    entity           0  4.5  -3.503838\n",
       "30        e0'       a1'    entity           0  4.5 -13.717681\n",
       "34         e1        a0    entity           0  4.5  -8.421687\n",
       "38         e1       a0'    entity           0  4.5 -17.091707\n",
       "42         e1        a1    entity           0  4.5  -0.371906\n",
       "46         e1       a1'    entity           0  4.5 -16.691963\n",
       "50        e1'        a0    entity           0  4.5  -2.005777\n",
       "54        e1'       a0'    entity           0  4.5 -11.650394\n",
       "58        e1'        a1    entity           0  4.5  -2.338843\n",
       "62        e1'       a1'    entity           0  4.5 -12.068946"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df[\"swap_type\"] == \"entity\") & (df[\"swap_index\"] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3ba88c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer the question based on the context below. Keep the answer short.\\n\\nContext: Jason lives in the capital city of Sweden. Nancy lives in the capital city of Uruguay.\\nQuestion: Which city does Jason live in?\\nAnswer: Jason lives in the city of'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2f5425e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0315, device='cuda:0')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_id = tokenizer(mp.answers[query_entity_idx], add_special_tokens=False)[\"input_ids\"][0]\n",
    "log_probs = F.log_softmax(modified_out.logits[0,-1,:], dim=-1)\n",
    "log_probs[answer_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6b4d16b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-23.2788, -21.2583, -14.3669,  ..., -23.6564, -24.3424, -25.9400],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "84e6ad03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30d7ad0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁Mark'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(main_prompt_tokens[\"input_ids\"][0])[main_n2_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537ec019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(main_prompt_tokens[\"input_ids\"][0]).index(f\"▁{prompt_pair.main_names[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3adbd47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3251e-02, -5.2957e-02, -1.0089e-02,  ...,  1.9258e-02,\n",
       "           7.3705e-03,  2.5430e-02],\n",
       "         [-3.4841e-02, -7.5956e-02, -1.0159e-02,  ...,  1.0131e-01,\n",
       "          -3.9658e-03,  2.3802e-02],\n",
       "         [-2.6152e-02, -5.9799e-02,  2.6138e-02,  ...,  1.2930e-02,\n",
       "           3.9451e-02,  1.6938e-02],\n",
       "         ...,\n",
       "         [-4.5742e-05,  2.1826e-02, -2.1186e-02,  ..., -4.1297e-02,\n",
       "           4.5158e-03,  2.1583e-02],\n",
       "         [ 5.7665e-02, -4.2070e-02, -1.5980e-02,  ..., -6.4957e-03,\n",
       "           3.3395e-02,  1.0812e-02],\n",
       "         [-1.4484e-02, -2.2502e-02,  3.3836e-02,  ..., -2.8230e-02,\n",
       "           5.5241e-02,  1.5567e-02]],\n",
       "\n",
       "        [[-1.6303e-02,  2.0433e-02,  6.8255e-02,  ...,  3.0602e-03,\n",
       "          -1.9257e-02,  3.2786e-02],\n",
       "         [-5.5994e-02, -7.8774e-02,  4.2664e-02,  ...,  2.1059e-01,\n",
       "           5.3005e-02, -3.5130e-02],\n",
       "         [-7.0046e-02, -2.4076e-02,  1.2887e-01,  ...,  7.8399e-02,\n",
       "           7.9528e-02,  9.0209e-03],\n",
       "         ...,\n",
       "         [-1.5216e-02,  6.5975e-02,  3.2406e-02,  ..., -5.6718e-02,\n",
       "           8.4293e-02,  2.4157e-02],\n",
       "         [ 9.6639e-02, -1.9060e-02,  1.1448e-02,  ...,  6.0398e-02,\n",
       "           1.1977e-01,  6.5605e-02],\n",
       "         [-7.7902e-02,  5.2937e-02,  9.4408e-02,  ..., -5.5246e-02,\n",
       "           8.4096e-02,  5.1465e-02]],\n",
       "\n",
       "        [[ 7.2313e-04, -5.0714e-03,  6.1681e-04,  ...,  2.5063e-03,\n",
       "          -5.8769e-04, -1.8575e-04],\n",
       "         [-6.9813e-02, -1.4314e-01,  5.8101e-02,  ...,  2.6426e-01,\n",
       "          -2.7084e-02,  4.5995e-02],\n",
       "         [-8.3589e-02, -2.2646e-02,  5.0529e-03,  ..., -9.7340e-02,\n",
       "           1.2941e-01,  6.7531e-02],\n",
       "         ...,\n",
       "         [ 1.6912e-02,  1.0098e-01, -2.2190e-02,  ..., -7.2641e-02,\n",
       "           1.1278e-01,  4.2134e-02],\n",
       "         [ 5.4634e-02, -9.4305e-02, -2.0713e-02,  ...,  9.1591e-02,\n",
       "           5.6544e-02,  8.4427e-02],\n",
       "         [-5.8797e-02, -1.2391e-02, -5.0634e-02,  ..., -1.4583e-01,\n",
       "           1.0415e-01, -1.5146e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-7.0804e-04, -1.9470e-02,  1.1610e-02,  ...,  1.9622e-02,\n",
       "           1.3544e-02, -1.2659e-02],\n",
       "         [-3.2758e-01, -3.8266e-01,  1.9582e-01,  ...,  7.5087e-01,\n",
       "           6.6476e-01,  3.5830e-01],\n",
       "         [-1.0853e-01, -2.9970e-01, -5.6951e-01,  ...,  1.8308e-02,\n",
       "           2.4543e-01,  2.8306e-01],\n",
       "         ...,\n",
       "         [-5.5198e-01, -3.9464e-01, -5.3745e-01,  ..., -5.3383e-02,\n",
       "           3.1326e-01, -3.3634e-03],\n",
       "         [-2.3384e-01, -2.0161e-01, -2.8981e-01,  ...,  7.9233e-01,\n",
       "          -5.9881e-01,  1.5485e-01],\n",
       "         [-1.0183e-01,  3.4839e-02, -2.6375e-01,  ...,  7.0845e-02,\n",
       "          -1.5950e-01,  7.6261e-02]],\n",
       "\n",
       "        [[ 3.8502e-03, -2.3904e-02,  1.4171e-02,  ...,  2.6001e-02,\n",
       "           1.6392e-02, -1.4766e-02],\n",
       "         [-1.0244e-01, -2.4695e-01, -1.0833e-01,  ...,  6.7119e-01,\n",
       "           7.2640e-01,  3.5143e-01],\n",
       "         [-4.9802e-02, -1.2432e-01, -7.8825e-01,  ...,  6.2572e-02,\n",
       "           2.9083e-01,  3.6451e-01],\n",
       "         ...,\n",
       "         [-5.3029e-01, -1.4579e-01, -3.7836e-01,  ..., -1.4720e-01,\n",
       "           5.4486e-01,  5.3503e-02],\n",
       "         [-2.3707e-01, -1.5150e-01, -2.8848e-01,  ...,  6.0091e-01,\n",
       "          -4.5029e-01,  1.5688e-01],\n",
       "         [ 1.1555e-01,  1.8885e-01, -1.2774e-01,  ..., -1.4083e-01,\n",
       "           7.9501e-02,  1.1795e-01]],\n",
       "\n",
       "        [[ 6.7911e-03, -2.6421e-02,  3.5576e-03,  ...,  3.7028e-02,\n",
       "           3.1293e-02, -3.3785e-02],\n",
       "         [-7.3365e-02, -4.2279e-01, -1.0875e-01,  ...,  3.0648e-01,\n",
       "           7.6069e-01,  3.3277e-01],\n",
       "         [ 8.0002e-02, -2.3027e-01, -5.9886e-01,  ...,  7.4977e-02,\n",
       "           3.2466e-01,  4.2086e-01],\n",
       "         ...,\n",
       "         [-4.6610e-01, -2.1589e-01, -3.4191e-01,  ..., -2.2311e-01,\n",
       "           4.1678e-01,  2.0336e-01],\n",
       "         [-1.5212e-01, -2.0556e-01, -2.6440e-01,  ...,  3.6079e-01,\n",
       "          -2.8505e-01,  1.8623e-01],\n",
       "         [ 3.8584e-01,  1.4980e-02,  1.1201e-01,  ..., -6.4838e-02,\n",
       "           1.8952e-01,  1.6094e-01]]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f3f651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generalize",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
