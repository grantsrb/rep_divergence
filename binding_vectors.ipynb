{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd3ecc8a",
   "metadata": {},
   "source": [
    "Specs for the notebook:\n",
    "- ideally takes any huggingface model but llama of some sort is good\n",
    "- produces the difference vectors\n",
    "- produces intervened vectors for entities/attributes\n",
    "- produces the corresponding native vectors for the entities/attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "184b0887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "def load_model_and_tokenizer(gpu_num, model_name=\"meta-llama/Llama-2-7b-chat-hf\"):\n",
    "    device = torch.device(f\"cuda:{gpu_num}\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name, cache_dir=\"/data2/sjeromeh/cache/pretrained_models\"\n",
    "    ).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"/data2/sjeromeh/cache/pretrained_models\")\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    model.eval()\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e54882",
   "metadata": {},
   "source": [
    "Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62f8031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "model, tokenizer = load_model_and_tokenizer(0, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b4b570",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86b3bd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of countries: 247, Sample: [('Abkhazia', 'Sukhumi'), ('Afghanistan', 'Kabul'), ('Akrotiri and Dhekelia', 'Episkopi Cantonment'), ('Albania', 'Tirana'), ('Algeria', 'Algiers')]\n",
      "Number of names: 100, Sample: ['Michael', 'James', 'John', 'Robert', 'David']\n"
     ]
    }
   ],
   "source": [
    "countries_df = pd.read_csv(\"data/countries.csv\")\n",
    "names_df = pd.read_csv(\"data/names.csv\", index_col=0)\n",
    "\n",
    "countries_to_capitals = countries_df.set_index(\"country\")[\"capital\"].to_dict()\n",
    "names = names_df[\"name\"].tolist()\n",
    "\n",
    "print(f\"Number of countries: {len(countries_to_capitals)}, Sample: {list(countries_to_capitals.items())[:5]}\")\n",
    "print(f\"Number of names: {len(names)}, Sample: {names[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea54a8c5",
   "metadata": {},
   "source": [
    "Prompt generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b9d3f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Stephen lives in the capital city of Western Sahara. Rebecca lives in the capital city of Ecuador. Rachel lives in the capital city of Iceland. Timothy lives in the capital city of Seychelles. Zachary lives in the capital city of Bangladesh.\n",
      "Context: Brenda lives in the capital city of Cocos (Keeling) Islands. Paul lives in the capital city of Syria. Patrick lives in the capital city of Barbados. Ronald lives in the capital city of Kuwait. Benjamin lives in the capital city of Azerbaijan.\n",
      "['Question: Which city does Stephen live in?', 'Question: Which city does Rebecca live in?', 'Question: Which city does Rachel live in?', 'Question: Which city does Timothy live in?', 'Question: Which city does Zachary live in?']\n",
      "['El Aaiún', 'Quito', 'Reykjavík', 'Victoria', 'Dhaka']\n"
     ]
    }
   ],
   "source": [
    "def generate_prompts(num_entities):\n",
    "    cs = random.sample(list(countries_to_capitals.keys()), num_entities*2)\n",
    "    ns = random.sample(names, num_entities*2)\n",
    "\n",
    "    cs_1 = cs[:num_entities]\n",
    "    ns_1 = ns[:num_entities]\n",
    "    cs_2 = cs[num_entities:]\n",
    "    ns_2 = ns[num_entities:]\n",
    "\n",
    "    es_1 = [f\"{n} lives in the capital city of {c}.\" for c, n in zip(cs_1, ns_1)]\n",
    "    es_2 = [f\"{n} lives in the capital city of {c}.\" for c, n in zip(cs_2, ns_2)]\n",
    "    context =  f\"Context: {' '.join(es_1)}\"\n",
    "    alt_context =  f\"Context: {' '.join(es_2)}\"\n",
    "    questions = [f\"Question: Which city does {n} live in?\" for n in ns_1]\n",
    "    answers = [countries_to_capitals[c] for c in cs_1]\n",
    "    alt_answers = [countries_to_capitals[c] for c in cs_2]\n",
    "    return context, alt_context, questions, answers, alt_answers\n",
    "\n",
    "context, alt_context, questions, answers, alt_answers = generate_prompts(5)\n",
    "print(context)\n",
    "print(alt_context)\n",
    "print(questions)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa4c2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generalize",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
